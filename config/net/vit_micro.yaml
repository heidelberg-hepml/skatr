arch: ViT
in_shape: [1, 28, 28, 470]
out_channels: 6
# patch_shape: [7, 7, 47] # 10 x 10 x 25 = 2500 tokens with 7x7x47 = 2300 voxels
patch_shape: [4, 4, 10] # 7 x 7 x 47 = 2303 tokens with 4*4*10 = 160 voxels
hidden_dim: 144
depth: 4
num_heads: 4
mlp_ratio: 2.0
attn_drop: 0.
proj_drop: 0.
mlp_drop: 0.
learn_pos_encoding: True
out_act: sigmoid
use_mask_token: True
checkpoint_grads: False

use_head: False
head:
  _target_: src.networks.MLP
  cfg:
    units:
      - ${net.hidden_dim}
      - ${net.hidden_dim}
      - ${net.out_channels}
    act: relu
    out_act: ${net.out_act}
    drop: ${net.mlp_drop}

use_input_conv: False