run_name: pretraining_micro
experiment: PretrainingExperiment
evaluate: False
plot: False

model: JEPA
ema_momentum: 0.9997
momentum_schedule: False
sim: l1
augment: False
init_tgt_as_ctx: True

net: # encoders
  use_mask_token: False
  use_head: False
  hidden_dim: 144
  depth: 4

predictor:
  use_head: False
  hidden_dim: 48
  depth: 4
  learn_pos_encoding: False
  in_dim: ${net.hidden_dim}
  in_shape: ${net.in_shape}
  patch_shape: ${net.patch_shape}

training:
  epochs: 1000
  lr: 0.001
  batch_size: 64
  optimizer:
    name: AdamW

defaults:
  - default
  - masking: multiblock
  - net: vit_micro
  - net@predictor: vit_micro
  - preprocessing: xonly  
  - _self_
